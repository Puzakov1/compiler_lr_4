{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "152d33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "long_terms = ['<>', 'id', 'end', 'begin', '>=', '<=']\n",
    "simple_terms = ['(', '/', ')', '%', '^', '-', '*', ';', '+'] + [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "short_terms = ['=', '>', '<']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9225371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression(i):\n",
    "    node = []\n",
    "    i, arif_expr_node = arif_expression(i)\n",
    "    node.append({\"arif_expression\":arif_expr_node})\n",
    "    i, relationship_sign_node = relationship_sign(i)\n",
    "    node.append({\"relationship_sign\":relationship_sign_node})\n",
    "    i, arif_expr_node = arif_expression(i)\n",
    "    node.append({\"arif_expression\":arif_expr_node})\n",
    "    return i, node\n",
    "\n",
    "\n",
    "def arif_expression(i):\n",
    "    node = []\n",
    "    try:\n",
    "        i, add_type_node = add_type_expr(i)\n",
    "        node.append({\"add_type_expr\":add_type_node})\n",
    "    except:\n",
    "        pass\n",
    "    i, term_node = term(i)\n",
    "    node.append({\"term\":term_node})\n",
    "    try:\n",
    "        i, arif_expression_1_node = arif_expression_1(i)\n",
    "        node.append({\"arif_expression_1\":arif_expression_1_node})\n",
    "    except:\n",
    "        pass\n",
    "    return i, node\n",
    "\n",
    "\n",
    "def term(i):\n",
    "    node = []\n",
    "    i, mult_node = mult(i)\n",
    "    node.append({\"mult\":mult_node})\n",
    "    try:\n",
    "        i, term_1_node = term_1(i)\n",
    "        node.append({\"term'\":term_1_node})\n",
    "    except:\n",
    "        pass\n",
    "    return i, node\n",
    "\n",
    "\n",
    "def mult(i):\n",
    "    node = []\n",
    "    i, first_expr_node = first_expr(i)\n",
    "    node.append({\"first_expr\":first_expr_node})\n",
    "    try:\n",
    "        i, mult_1_node = mult_1(i)\n",
    "        node.append({\"mult_1\":mult_1_node})\n",
    "    except:\n",
    "        pass\n",
    "    return i, node\n",
    "\n",
    "\n",
    "def first_expr(i):\n",
    "    node = []\n",
    "    if tokenized[i] == \"(\":\n",
    "        node.append(\"(\")\n",
    "        i = i+1\n",
    "        i,arif_expression_node = arif_expression(i)\n",
    "        node.append({\"arif_expression\":arif_expression_node})\n",
    "        if tokenized[i] == \")\":\n",
    "            i = i+1\n",
    "            node.append(\")\")\n",
    "        else:\n",
    "            raise ValueError(i)\n",
    "        return i, node\n",
    "    try:\n",
    "        i, number_node = number(i)\n",
    "        node.append({\"number\":number_node})\n",
    "    except:\n",
    "        i, id_node = identifier(i)\n",
    "        node.append({\"identifier\":id_node})\n",
    "    return i, node\n",
    "\n",
    "\n",
    "def add_type_expr(i):\n",
    "    if tokenized[i] in (\"+\", \"-\"):\n",
    "        i = i+1\n",
    "        return i, [tokenized[i-1]]\n",
    "    else:\n",
    "        raise ValueError(i)\n",
    "\n",
    "\n",
    "def mult_type_expr(i):\n",
    "    if tokenized[i] in (\"*\", \"/\", \"%\"):\n",
    "        i = i+1\n",
    "        return i, [tokenized[i-1]]\n",
    "    else:\n",
    "        raise ValueError(i)\n",
    "    \n",
    "\n",
    "def relationship_sign(i):\n",
    "    if tokenized[i] in (\"<\", \"<=\", \"=\", \">=\", \">\", \"<>\"):\n",
    "        i = i+1\n",
    "        return i, [tokenized[i-1]]\n",
    "    else:\n",
    "        raise ValueError(i)\n",
    "\n",
    "\n",
    "def identifier(i):\n",
    "    if tokenized[i] == \"id\":\n",
    "        i = i+1\n",
    "        return i, [tokenized[i-1]]\n",
    "    else:\n",
    "        raise ValueError(i)\n",
    "\n",
    "\n",
    "def number(i):\n",
    "    if tokenized[i] in (\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"):\n",
    "        i = i+1\n",
    "        return i, [tokenized[i-1]]\n",
    "    else:\n",
    "        raise ValueError(i)\n",
    "\n",
    "\n",
    "def term_1(i):\n",
    "    node = []\n",
    "    i, mult_expr_node = mult_type_expr(i)\n",
    "    node.append({\"mult_type_expr\":mult_expr_node})\n",
    "    i, mult_node = mult(i)\n",
    "    node.append({\"mult\":mult_node})\n",
    "    try:\n",
    "        i, term_1_node = term_1(i)\n",
    "        node.append({\"temr'\":term_1_node})\n",
    "    except:\n",
    "        pass\n",
    "    return i, node\n",
    "\n",
    "\n",
    "def mult_1(i):\n",
    "    node = []\n",
    "    if tokenized[i] == \"^\":\n",
    "        i+= 1\n",
    "        node.append(\"^\")\n",
    "    else:\n",
    "        raise ValueError(i)\n",
    "    i, first_expr_node = first_expr(i)\n",
    "    node.append({\"first_expr\":first_expr_node})\n",
    "    try:\n",
    "        i, mult_1_node = mult_1(i)\n",
    "        node.append({\"mult'\":mult_1_node})\n",
    "    except:\n",
    "        pass\n",
    "    return i, node\n",
    "\n",
    "\n",
    "def arif_expression_1(i):\n",
    "    node = []\n",
    "    i, add_expr_node = add_type_expr(i)\n",
    "    node.append({\"add_expr\":add_expr_node})\n",
    "    i, term_node = term(i)\n",
    "    node.append({\"term\":term_node})\n",
    "    try:\n",
    "        i, are1_node = arif_expression_1(i)\n",
    "        node.append({\"arif_expression_1\":are1_node})\n",
    "    except:\n",
    "        pass\n",
    "    return i, node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8deede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize(in_str):\n",
    "    tokenized = []\n",
    "    i = 0\n",
    "    while i<len(in_str):\n",
    "        if in_str[i] in simple_terms:\n",
    "            tokenized.append(in_str[i])\n",
    "            i = i+1\n",
    "            continue\n",
    "        for t in long_terms:\n",
    "            flag = False\n",
    "            if in_str[i:].startswith(t):\n",
    "                tokenized.append(t)\n",
    "                i+=len(t)\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            continue\n",
    "\n",
    "        if in_str[i] in short_terms:\n",
    "            tokenized.append(in_str[i])\n",
    "            i = i+1\n",
    "            continue\n",
    "        \n",
    "        i = i+1\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a8a8908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3',\n",
       " '*',\n",
       " '(',\n",
       " '1',\n",
       " '+',\n",
       " '2',\n",
       " '*',\n",
       " '3',\n",
       " '+',\n",
       " '4',\n",
       " ')',\n",
       " '>',\n",
       " '5',\n",
       " '^',\n",
       " '6',\n",
       " '+',\n",
       " '1',\n",
       " '/',\n",
       " '2']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized = tokenize(\"3*(1+2*3+4)>5^6\")\n",
    "tokenized = tokenize(\"3*(1+2*3+4)>5^6+1/2\")\n",
    "# tokenized = tokenize(\"3+7*2>0\")\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d8d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checksum, tree = expression(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d3acf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_polish(node):\n",
    "    nums_to_skip = []\n",
    "    # print(node)\n",
    "    if type(node)==str and node not in \"()\":\n",
    "        res.append(node)\n",
    "        return\n",
    "    if type(node)==list:\n",
    "        \n",
    "        for i, a in enumerate(node):\n",
    "            if a == \"^\":\n",
    "                nums_to_skip.append(i)\n",
    "            if type(a) == str:\n",
    "                continue\n",
    "            if list(a.keys())[0] in (\"mult_type_expr\", \"add_expr\", \"relationship_sign\"):\n",
    "                nums_to_skip.append(i)\n",
    "        for i, a in enumerate(node):\n",
    "            if i not in nums_to_skip:\n",
    "                make_polish(a)\n",
    "    if type(node)==dict:\n",
    "        for _, i in node.items():\n",
    "            make_polish(i)\n",
    "    for i in nums_to_skip:\n",
    "        make_polish(node[i])\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "660cb5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"arif_expression\": [{\"term\": [{\"mult\": [{\"first_expr\": [{\"number\": [\"3\"]}]}]}, {\"term\\'\": [{\"mult_type_expr\": [\"*\"]}, {\"mult\": [{\"first_expr\": [\"(\", {\"arif_expression\": [{\"term\": [{\"mult\": [{\"first_expr\": [{\"number\": [\"1\"]}]}]}]}, {\"arif_expression_1\": [{\"add_expr\": [\"+\"]}, {\"term\": [{\"mult\": [{\"first_expr\": [{\"number\": [\"2\"]}]}]}, {\"term\\'\": [{\"mult_type_expr\": [\"*\"]}, {\"mult\": [{\"first_expr\": [{\"number\": [\"3\"]}]}]}]}]}, {\"arif_expression_1\": [{\"add_expr\": [\"+\"]}, {\"term\": [{\"mult\": [{\"first_expr\": [{\"number\": [\"4\"]}]}]}]}]}]}]}, \")\"]}]}]}]}]}, {\"relationship_sign\": [\">\"]}, {\"arif_expression\": [{\"term\": [{\"mult\": [{\"first_expr\": [{\"number\": [\"5\"]}]}, {\"mult_1\": [\"^\", {\"first_expr\": [{\"number\": [\"6\"]}]}]}]}]}, {\"arif_expression_1\": [{\"add_expr\": [\"+\"]}, {\"term\": [{\"mult\": [{\"first_expr\": [{\"number\": [\"1\"]}]}]}, {\"term\\'\": [{\"mult_type_expr\": [\"/\"]}, {\"mult\": [{\"first_expr\": [{\"number\": [\"2\"]}]}]}]}]}]}]}]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d50a1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "make_polish(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8f2aa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3123*4++*56^12/+>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9ede0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3*(1+2*3+4)>5^6+1/2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73024041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
